#!/usr/bin/env python
"""
metaFilter_shortScaffold_nLook
13 June 2014

dent earl, dearl a soe ucsc edu

a meta filter for the msca project analysis pipeline.
Runs shortScaffold_noStartStop and then nLook
"""
import sys
import os
sys.path.append(
  os.path.join(
    os.path.dirname(  # mus_strain_cactus
      os.path.dirname(  # pipeline
        os.path.dirname(  # filters
          os.path.abspath(sys.argv[0])))),
    'src'))  # to import lib_run
import shutil
import sys
import lib_filter
import lib_run


def getBin(bin):
  """ Given the name of a filter, return the full path to the filter.
  """
  return os.path.join(os.path.dirname(os.path.abspath(sys.argv[0])), bin)


def makeCall(bin, refGenome, genome, geneCheckBed, geneCheckBedDetails,
             originalGeneCheckBed, originalGeneCheckBedDetails,
             alignment, sequence, refSequence, chromSizes, outDir):
  """ Function to make a call to a filter and handle input / output.
  """
  if not os.path.exists(outDir):
    os.mkdir(outDir)
  bin = getBin(bin)
  cmd = [bin]
  for v in ['refGenome', 'genome', 'geneCheckBed', 'geneCheckBedDetails',
            'originalGeneCheckBed', 'originalGeneCheckBedDetails',
            'alignment', 'sequence', 'refSequence', 'chromSizes', 'outDir']:
    cmd.append('--%s' % v)
    cmd.append(eval(v))
  lib_run.Touch(os.path.join(outDir, 'clocking_in'))
  lib_run.RunCommandsSerial([cmd], outDir)
  lib_run.Touch(os.path.join(outDir, 'clocking_out'))


def copyResults(fromDir, toDir):
  """ Copy the bed results from FROMDIR to TODIR.
  """
  fromBed = os.path.join(fromDir, 'out.bed')
  fromBedDetails = os.path.join(fromDir, 'out_details.bed')
  toBed = os.path.join(toDir, 'out.bed')
  toBedDetails = os.path.join(toDir, 'out_details.bed')
  for frm, to in [(os.path.join(fromDir, 'out.bed'),
                   os.path.join(toDir, 'out.bed')),
                  (os.path.join(fromDir, 'out_details.bed'),
                   os.path.join(toDir, 'out_details.bed')),
                  (os.path.join(fromDir, 'out_clean.bed'),
                   os.path.join(toDir, 'out_clean.bed')),
                  (os.path.join(fromDir, 'out_details_clean.bed'),
                   os.path.join(toDir, 'out_details_clean.bed'))]:
    if os.path.exists(frm):
      shutil.copy2(frm, to)


def alreadyReady(filt, inBed, inBedDetail, outBed, outBedDetail, location):
  """ Check to see if this filter actually needs to be run (True).
  Send true if output does not exist or if
  """
  filt = getBin(filt)
  if not os.path.exists(inBed):
    raise RuntimeError('input for %s does not exist' % filt)
  inBedTime = os.path.getmtime(inBed)
  if not os.path.exists(inBedDetail):
    raise RuntimeError('input for %s does not exist' % filt)
  inBedDetailTime = os.path.getmtime(inBedDetail)
  if not os.path.exists(location):
    # output directory does not exist: re-run
    return False
  if not os.path.exists(outBed):
    # bed does not exist: re-run
    return False
  outBedTime = os.path.getmtime(outBed)
  if not os.path.exists(outBedDetail):
    # bed details does not exist: re-run
    return False
  outBedDetailTime = os.path.getmtime(outBedDetail)
  if inBedTime > outBedTime:
    # newer input than data: re-run
    return False
  if inBedDetailTime > outBedDetailTime:
    # newer input than data: re-run
    return False
  filtTime = os.path.getmtime(filt)
  if filtTime > outBedTime:
    # newer filter than data: re-run
    return False
  if filtTime > outBedDetailTime:
    # newer filter than data: re-run
    return False
  # directory exists, bed exists, bed detail exists,
  # input is older than data, filter is older than data: do not re-run.
  return True


def sanitize(location):
  """ The bed files need to have their names scrubbed to remove the hyphen
  names, i.e. ENSMUST00000169901.2-0 and ENSMUST00000169901.2-1 need to become
  just ENSMUST00000169901.2. We used the hyphen names through the pipeline to
  try to keep separate instances of transcripts and their annotations separate.
  But this hypen name space will break our Browser search functionality.
  """
  for infile, cleanfile in [('out.bed', 'out_clean.bed'),
                            ('out_details.bed', 'out_details_clean.bed')]:
    with open(os.path.join(location, cleanfile), 'w') as clean:
      with open(os.path.join(location, infile), 'r') as f:
        for line in f:
          line = line.strip()
          data = line.split()
          data[3] = lib_filter.removeAlignmentNumber(data[3])
          clean.write('%s\n' % '\t'.join(data))


def main():
  args = lib_filter.boilerplateArguments()
  # this is the order that filters will be run.
  filters = ['uniquify']  # uniquify should always be run first
  # Add new filters somewhere in between the comment blocks:
  ##############################
  filters.append('nLook')
  filters.append('shortScaffold_noStartStop')
  filters.append('noStopCorrecter')
  filters.append('paralogs')
  filters.append('nonsense')
  filters.append('mRnaCompare')
  ##############################
  # Do not change the order of filters below this line
  filters.append('gigo')
  filters.append('colorizer')
  # create needed lists containing file / directory locations
  inputs = [(args.geneCheckBed, args.geneCheckBedDetails)]
  locations = []
  for f in filters:
    locations.append(os.path.join(args.outDir, f))
    inputs.append((os.path.join(args.outDir, f, 'out.bed'),
                   os.path.join(args.outDir, f, 'out_details.bed')))
  # run filters in sequence
  for i, f in enumerate(filters, 0):
    if alreadyReady(f, inputs[i][0], inputs[i][1],
                    inputs[i+1][0], inputs[i+1][1], locations[i]):
      continue
    makeCall(f, args.refGenome, args.genome,
             inputs[i][0], inputs[i][1],
             args.originalGeneCheckBed, args.originalGeneCheckBedDetails,
             args.alignment, args.sequence, args.refSequence, args.chromSizes,
             locations[i])
    sanitize(locations[i])
  # copy back last filter to the metaFilter directory for end use
  copyResults(locations[-1], args.outDir)


if __name__ == '__main__':
  main()
